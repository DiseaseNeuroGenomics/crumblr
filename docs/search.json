[{"path":"http://gabrielhoffman.github.io/crumblr/articles/crumblr.html","id":"differential-testing","dir":"Articles","previous_headings":"","what":"Differential testing","title":"Using crumblr in practice","text":"evaluate whether observed cell proportions change response interferon β. Given results , reject null hypothesis interferon β affect cell type proportions.","code":"library(crumblr)  # Load cell counts from Kang, et al. (2018) #  https://doi.org/10.1038/nbt.4042 data(IFNCellCounts)  # Apply crumblr transformation  # cobj is an EList object compatable with limma workflow # cobj$E stores transformed values  # cobj$weights stores precision weights cobj = crumblr(cellCounts)  # Use variancePartition workflow to analyze each cell type # Perform regression on each cell type separately #  then use eBayes to shrink residual variance # Also compatible with limma::lmFit()  library(variancePartition) fit = dream(cobj,  ~ StimStatus + ind, info) fit = eBayes(fit)  # Extract results for each cell type topTable(fit, coef=\"StimStatusstim\", number=Inf, sort.by=\"none\") ##                         logFC    AveExpr          t   P.Value adj.P.Val         B ## B cells           -0.09825871  0.5516882 -0.6779201 0.5076669  0.823424 -4.746255 ## CD14+ Monocytes   -0.12437220  1.2698117 -0.9560159 0.3535191  0.823424 -4.685558 ## CD4 T cells       -0.07763160  2.0201947 -0.4732415 0.6425378  0.823424 -4.900413 ## CD8 T cells       -0.16431725  0.0857175 -0.3892080 0.7023377  0.823424 -4.758201 ## Dendritic cells    0.32516900 -2.1849234  1.0895217 0.2923251  0.823424 -4.590653 ## FCGR3A+ Monocytes  0.06580754 -0.2567492  0.3460969 0.7338531  0.823424 -4.734622 ## Megakaryocytes     0.04681137 -1.8655172  0.2268978 0.8234240  0.823424 -4.635391 ## NK cells           0.08494553  0.3797777  0.5814645 0.5691622  0.823424 -4.753355"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/crumblr.html","id":"pca","dir":"Articles","previous_headings":"","what":"PCA","title":"Using crumblr in practice","text":"Performing PCA transformed cell counts indicates samples cluster based subject rather stimulation status.","code":"library(ggplot2)  # Apply Student transform M_student = studentize(cobj)  # Perform PCA pca = prcomp(t(M_student))  # merge with metadata  df_pca = merge(pca$x, info, by=\"row.names\")  # Plot PCA  #   color by Subject #   shape by Stimulated vs unstimulated ggplot(df_pca, aes(PC1, PC2, color=as.character(ind),  shape=StimStatus)) +          geom_point(size=3) +          theme_classic() +          theme(aspect.ratio=1) +          scale_color_discrete(name=\"Subject\") +         xlab(\"PC1\") + ylab(\"PC2\")"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/crumblr.html","id":"hierachical-clustering","dir":"Articles","previous_headings":"","what":"Hierachical clustering","title":"Using crumblr in practice","text":"samples subject also cluster together.","code":"heatmap(M_student)"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/crumblr.html","id":"variance-partitioning","dir":"Articles","previous_headings":"","what":"Variance partitioning","title":"Using crumblr in practice","text":"Decomposing variance illustrates variation explained subject stimulation status.","code":"library(variancePartition)  # Partition variance into components for Subject (i.e. ind) #   and stimulation status, and residual variation vp = fitExtractVarPartModel( cobj, ~ ind + StimStatus, info)  # Plot variance fractions plotPercentBars(vp)"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/crumblr_theory.html","id":"crumblr-is-an-important-special-case","dir":"Articles","previous_headings":"","what":"crumblr is an important special case","title":"crumblr: compare emprical and asymptotic theory","text":"Based Equation (2), variance CLR-transformed proportions linear function \\(\\tau\\). Importantly, downstream analysis CLR-transformed proportions precision-weighted linear (mixed) model variance stabilizing transform depends relative variances. Since relative variances invariant scale \\(\\tau\\), applications value \\(\\tau\\) can set 1 instead estimated data. applications, crumblr can estimate \\(\\tau\\) data using crumblr(counts, tau=NULL). calls dmn.mle() estimate parameters DMN distribution substantially faster alternatives.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/articles/crumblr_theory.html","id":"d2-categories","dir":"Articles","previous_headings":"","what":"D=2 categories","title":"crumblr: compare emprical and asymptotic theory","text":"True vector fractions \\(\\bf p\\) (0.0033, 0.996).","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/articles/crumblr_theory.html","id":"d25-categories","dir":"Articles","previous_headings":"","what":"D=25 categories","title":"crumblr: compare emprical and asymptotic theory","text":"True vector fractions \\(\\bf p\\) (0.0033, 0.2300, 0.0333,…) remaining elements also 0.0333.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/articles/studentize.html","id":"examine-vst","dir":"Articles","previous_headings":"","what":"Examine VST","title":"Student transform","text":"First, simulate count data:","code":"library(crumblr) library(cowplot)  set.seed(1)  # set probability of each category x = rgamma(300, 1, 10) prob = x / sum(x)  # number of samples n_samples = 500  # number of counts nCounts = 3000  # simulate counts from multinomial counts = t(rmultinom(n_samples, size = nCounts, prob = prob)) colnames(counts) = paste0(\"cat_\", 1:length(prob)) rownames(counts) = paste0(\"sample_\", 1:n_samples)  # keep categories with at least 5 counts in at least 10 samples keep = colSums(counts > 5) > 20  # compute fractions from counts # using pseudocount of 0.5 fractions = apply(counts[,keep], 1, function(x){   x = x + 0.5   x / sum(x) })  # run crumblr on counts cobj = crumblr(counts[,keep], tau=1)"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/studentize.html","id":"apply-vst","dir":"Articles","previous_headings":"","what":"Apply vst","title":"Student transform","text":"crumblr performs centered log-ratio (CLR) transform, computes observation-level precision weights. VST scales transformed values using precision weights. see vst() almost linear sufficiently large CLR values.","code":"df_vst = studentize(cobj)  plotScatterDensity(cobj$E[,1], df_vst[,1]) +          geom_abline(color=\"red\", size=.3) +          ggtitle(\"crumblr + vst transform\") +         xlab(\"CLR\") +         ylab(\"crumblr + studentize\")"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/studentize.html","id":"concordance-between-samples-for-each-transform","dir":"Articles","previous_headings":"","what":"Concordance between samples for each transform","title":"Student transform","text":"Concordance two identically distributed samples show using () fractions, (B) CLR (C) VST proposed . low counts, CLR (B) highly discordant two samples due imprecise measurement. (C) VST -weights measurements improve concordance.","code":"fig1 = plotScatterDensity(fractions[,1], fractions[,2]) +              geom_abline(color=\"red\", size=.3) +              ggtitle(\"Fractions\") +             xlab(\"Sample 1\") +             ylab(\"Sample 2\")   fig2 = plotScatterDensity(cobj$E[,1], cobj$E[,2]) +              geom_abline(color=\"red\", size=.3) +              ggtitle(\"CLR\") +             xlab(\"Sample 1\") +             ylab(\"Sample 2\")  fig3 = plotScatterDensity(df_vst[,1], df_vst[,2]) +              geom_abline(color=\"red\", size=.3) +              ggtitle(\"crumblr + studentize\")  +             xlab(\"Sample 1\") +             ylab(\"Sample 2\")   plot_grid(fig1, fig2, fig3, labels=LETTERS[1:3], nrow=1)"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/studentize.html","id":"measuring-variance-stabilization","dir":"Articles","previous_headings":"","what":"Measuring variance stabilization","title":"Student transform","text":"variance stabilizing property can observed empirically. feature (.e. gene, cell type, etc), standard deviation transformed value compared rank mean. variance stabilized coefficient variation (.e. sd/mean) smaller. CLR-transform provide variance stabilization compared using fractions, VST produces much stronger stabilization.","code":"# Mean vs SD plot  fig1 = meanSdPlot(fractions) + ggtitle(\"Fractions\")  fig2 = meanSdPlot(cobj$E) + ggtitle(\"CLR\")  fig3 = meanSdPlot(df_vst) + ggtitle(\"crumblr vst\")  plot_grid(fig1, fig2, fig3, labels=LETTERS[1:3], nrow=1)"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/vst.html","id":"examine-vst","dir":"Articles","previous_headings":"","what":"Examine VST","title":"Variance stabilizing transform","text":"First, simulate count data:","code":"library(crumblr) library(cowplot)  set.seed(1)  # set probability of each category x = rgamma(300, 1, 10) prob = x / sum(x)  # number of samples n_samples = 500  # number of counts nCounts = 3000  # simulate counts from multinomial counts = t(rmultinom(n_samples, size = nCounts, prob = prob)) colnames(counts) = paste0(\"cat_\", 1:length(prob)) rownames(counts) = paste0(\"sample_\", 1:n_samples)  # keep categories with at least 5 counts in at least 10 samples keep = colSums(counts > 5) > 20  # compute fractions from counts # using pseudocount of 0.5 fractions = apply(counts[,keep], 1, function(x){   x = x + 0.5   x / sum(x) })  # run crumblr on counts cobj = crumblr(counts[,keep], tau=1)"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/vst.html","id":"apply-vst","dir":"Articles","previous_headings":"","what":"Apply vst","title":"Variance stabilizing transform","text":"crumblr performs centered log-ratio (CLR) transform, computes observation-level precision weights. VST scales transformed values using precision weights. see vst() almost linear sufficiently large CLR values.","code":"df_vst = vst(cobj)  plotScatterDensity(cobj$E[,1], df_vst[,1]) +          geom_abline(color=\"red\", size=.3) +          ggtitle(\"crumblr + vst transform\") +         xlab(\"CLR\") +         ylab(\"crumblr + vst\")"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/vst.html","id":"concordance-between-samples-for-each-transform","dir":"Articles","previous_headings":"","what":"Concordance between samples for each transform","title":"Variance stabilizing transform","text":"Concordance two identically distributed samples show using () fractions, (B) CLR (C) VST proposed . low counts, CLR (B) highly discordant two samples due imprecise measurement. (C) VST -weights measurements improve concordance.","code":"fig1 = plotScatterDensity(fractions[,1], fractions[,2]) +              geom_abline(color=\"red\", size=.3) +              ggtitle(\"Fractions\") +             xlab(\"Sample 1\") +             ylab(\"Sample 2\")   fig2 = plotScatterDensity(cobj$E[,1], cobj$E[,2]) +              geom_abline(color=\"red\", size=.3) +              ggtitle(\"CLR\") +             xlab(\"Sample 1\") +             ylab(\"Sample 2\")  fig3 = plotScatterDensity(df_vst[,1], df_vst[,2]) +              geom_abline(color=\"red\", size=.3) +              ggtitle(\"crumblr + vst\")  +             xlab(\"Sample 1\") +             ylab(\"Sample 2\")   plot_grid(fig1, fig2, fig3, labels=LETTERS[1:3], nrow=1)"},{"path":"http://gabrielhoffman.github.io/crumblr/articles/vst.html","id":"measuring-variance-stabilization","dir":"Articles","previous_headings":"","what":"Measuring variance stabilization","title":"Variance stabilizing transform","text":"variance stabilizing property can observed empirically. feature (.e. gene, cell type, etc), standard deviation transformed value compared rank mean. variance stabilized coefficient variation (.e. sd/mean) smaller. CLR-transform provide variance stabilization compared using fractions, VST produces much stronger stabilization.","code":"# Mean vs SD plot  fig1 = meanSdPlot(fractions) + ggtitle(\"Fractions\")  fig2 = meanSdPlot(cobj$E) + ggtitle(\"CLR\")  fig3 = meanSdPlot(df_vst) + ggtitle(\"crumblr vst\")  plot_grid(fig1, fig2, fig3, labels=LETTERS[1:3], nrow=1)"},{"path":"http://gabrielhoffman.github.io/crumblr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Gabriel Hoffman. Author, maintainer.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hoffman G (2022). crumblr: Count ratio uncertainty modeling base linear regression. R package version 0.99.2, https://gabrielhoffman.github.io/crumblr.","code":"@Manual{,   title = {crumblr: Count ratio uncertainty modeling base linear regression},   author = {Gabriel Hoffman},   year = {2022},   note = {R package version 0.99.2},   url = {https://gabrielhoffman.github.io/crumblr}, }"},{"path":"http://gabrielhoffman.github.io/crumblr/index.html","id":"count-ratio-uncertainty-modeling-based-linear-regression","dir":"","previous_headings":"","what":"Count ratio uncertainty modeling based linear regression","title":"Count ratio uncertainty modeling base linear regression","text":"crumblr package enables analysis count ratio data using precision-weighted linear (mixed) models, PCA clustering. crumblr’s fast, normal approximation transformed count data Dirichlet-multinomial model allows use standard workflows analyize count ratio data modeling heteroskedasticity.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/index.html","id":"details","dir":"","previous_headings":"","what":"Details","title":"Count ratio uncertainty modeling base linear regression","text":"Analysis count ratio data (.e. fractions) requires special consideration since data non-normal, heteroskedastic, spans low rank space. counts can considered directly using Poisson, negative binomial, Dirichlet-multinomial models simple regression applications, can problematic since 1) can computationally expensive, 2) can produce poorly calibrated hypothesis tests, 3) challenging extend applications. widely used centered log-ratio (CLR) transform compositional data analysis makes count ratio data normal enables use linear models, standard methods. Yet CLR-transformed data still highly heteroskedastic: precision measurements varies widely. important factor considered existing methods. crumblr uses fast asymptotic normal approximation CLR-transformed counts Dirichlet-multinomial distribution model sampling variance transformed counts. crumblr enables incorporating sampling variance precision weights linear (mixed) models order increase power control false positive rate. crumblr also uses variance stabilizing transform (vst) based precision weights improve performance PCA clustering.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/index.html","id":"install","dir":"","previous_headings":"","what":"Install","title":"Count ratio uncertainty modeling base linear regression","text":"","code":"# repo is currently private, so need to include your userid and password devtools::install_github(\"GabrielHoffman/crumblr\", auth_token=XXXXX)"},{"path":"http://gabrielhoffman.github.io/crumblr/index.html","id":"introduction-to-compositional-data-analysis","dir":"","previous_headings":"","what":"Introduction to compositional data analysis","title":"Count ratio uncertainty modeling base linear regression","text":"Brief intro bioinformatics Quinn, et al. 2018 Book analysis R van den Boogaart Tolosana-Delgado, 2013","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/IFNCellCounts.html","id":null,"dir":"Reference","previous_headings":"","what":"Cell counts following interferon treatment — IFNCellCounts","title":"Cell counts following interferon treatment — IFNCellCounts","text":"Counts single cell RNA-seq data treated untreated samples (Kang et al. 2018) .","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/IFNCellCounts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cell counts following interferon treatment — IFNCellCounts","text":"","code":"data(IFNCellCounts)  info  cellCounts"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/IFNCellCounts.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cell counts following interferon treatment — IFNCellCounts","text":"info metadata sample cellCounts data.frame counts sample object class data.frame 16 rows 4 columns. object class matrix (inherits array) 16 rows 8 columns.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/IFNCellCounts.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cell counts following interferon treatment — IFNCellCounts","text":"Kang HM, Subramaniam M, Targ S, Nguyen M, Maliskova L, McCarthy E, Wan E, Wong S, Byrnes L, Lanata CM, others (2018). “Multiplexed droplet single-cell RNA-sequencing using natural genetic variation.” Nature Biotechnology, 36(1), 89--94.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/buildClusterTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform hierarchical clustering on reducedDim — buildClusterTree","title":"Perform hierarchical clustering on reducedDim — buildClusterTree","text":"Perform hierarchical clustering dimension reduction single cell expression data","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/buildClusterTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform hierarchical clustering on reducedDim — buildClusterTree","text":"","code":"buildClusterTree(sce, reduction, labelCol)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/buildClusterTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform hierarchical clustering on reducedDim — buildClusterTree","text":"sce SingleCellExperiment object reduction field reducedDims(sce) use labelCol column SingleCellExperiment storing cell type annotations","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/clr.html","id":null,"dir":"Reference","previous_headings":"","what":"Centered log ratio transform — clr","title":"Centered log ratio transform — clr","text":"Compute centered log ratio (CLR) transform count matrix.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/clr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Centered log ratio transform — clr","text":"","code":"clr(counts, pseudocount = 0.5)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/clr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Centered log ratio transform — clr","text":"counts count data samples rows variables columns pseudocount added counts avoid issues zeros","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/clr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Centered log ratio transform — clr","text":"matrix CLR transformed counts","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/clr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Centered log ratio transform — clr","text":"CLR vector x counts D categories defined  clr(x) = log(x) - mean(log(x)). details see van den Boogaart  Tolosana-Delgado (2013).","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/clr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Centered log ratio transform — clr","text":"Van den Boogaart KG, Tolosana-Delgado R (2013). Analyzing compositional data R, volume 122. Springer. https://link.springer.com/book/10.1007/978-3-642-36809-7.","code":""},{"path":[]},{"path":"http://gabrielhoffman.github.io/crumblr/reference/clr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Centered log ratio transform — clr","text":"","code":"# set probability of each category prob = c(0.1, 0.2, 0.3, 0.5)  # number of total counts countsTotal = 300  # number of samples n_samples = 100  # simulate info for each sample info = data.frame(Age = rgamma(n_samples, 50, 1)) rownames(info) = paste0(\"sample_\", 1:n_samples)  # simulate counts from multinomial counts = t(rmultinom(n_samples, size = n_samples, prob = prob)) colnames(counts) = paste0(\"cat_\", 1:length(prob)) rownames(counts) = paste0(\"sample_\", 1:n_samples)  # centered log ratio clr(counts)[1:4,] #>              cat_1       cat_2     cat_3     cat_4 #> sample_1 -1.438328  0.07801932 0.4419847 0.9183241 #> sample_2 -1.309955  0.29948262 0.2994826 0.7109900 #> sample_3 -0.411152 -0.41115204 0.2979955 0.5243086 #> sample_4 -1.304133  0.10463446 0.5320785 0.6674198"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/crumblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Count ratio uncertainty modeling based linear regression — crumblr","title":"Count ratio uncertainty modeling based linear regression — crumblr","text":"Count ratio uncertainty modeling based linear regression (crumblr) returns CLR-transformed counts observation-level inverse-variance weights use weighted linear models.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/crumblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count ratio uncertainty modeling based linear regression — crumblr","text":"","code":"crumblr(counts, pseudocount = 0.5, tau = 1)  # S4 method for matrix crumblr(counts, pseudocount = 0.5, tau = 1)  # S4 method for data.frame crumblr(counts, pseudocount = 0.5, tau = 1)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/crumblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count ratio uncertainty modeling based linear regression — crumblr","text":"counts count data samples rows variables columns pseudocount added counts avoid issues zeros tau overdispersion parameter Dirichlet multinomial.  NULL, estimate observed counts.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/crumblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count ratio uncertainty modeling based linear regression — crumblr","text":"EList object following components: E: numeric matrix CLR transformed counts weights: numeric matrix observation-level inverse-variance weights","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/crumblr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Count ratio uncertainty modeling based linear regression — crumblr","text":"Evalute centered log ratio (CLR) transform count matrix, asymptotic theoretical variances transformed observation.  asymptotic normal approximation increasingly accurate small overdispersion \\(\\tau\\), large total counts \\(C\\), large proportions \\(p\\), shows good agreement empirical results situtations. practice, often reasonable assume sufficient number counts variable included analysis anyway.  feasability assumption user determine.","code":""},{"path":[]},{"path":"http://gabrielhoffman.github.io/crumblr/reference/crumblr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count ratio uncertainty modeling based linear regression — crumblr","text":"","code":"# set probability of each category prob = c(0.1, 0.2, 0.3, 0.5)  # number of total counts countsTotal = 300  # number of samples n_samples = 100  # simulate info for each sample info = data.frame(Age = rgamma(n_samples, 50, 1)) rownames(info) = paste0(\"sample_\", 1:n_samples)  # simulate counts from multinomial counts = t(rmultinom(n_samples, size = countsTotal, prob = prob)) colnames(counts) = paste0(\"cat_\", 1:length(prob)) rownames(counts) = paste0(\"sample_\", 1:n_samples)  # run crumblr on counts cobj = crumblr(counts)  # run standard variancePartition analysis on crumblr results library(variancePartition) #> Loading required package: limma #> Loading required package: BiocParallel  fit = dream(cobj, ~ Age, info) #> Fixed effect model, using limma directly... #> User can apply eBayes() afterwards... fit = eBayes(fit)  topTable(fit, coef=\"Age\", sort.by=\"none\") #>               logFC    AveExpr           t   P.Value adj.P.Val         B #> cat_1 -8.280541e-04 -0.8696862 -0.41343802 0.6795118 0.9060157 -8.420488 #> cat_2  1.656693e-03 -0.1623514  1.07009955 0.2852330 0.8238154 -8.190919 #> cat_3 -5.543331e-05  0.2676482 -0.04061101 0.9676267 0.9676267 -8.888417 #> cat_4 -9.918353e-04  0.7643893 -0.82141763 0.4119077 0.8238154 -8.674523"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/dmn.mle.html","id":null,"dir":"Reference","previous_headings":"","what":"MLE for Dirichlet Multinomial — dmn.mle","title":"MLE for Dirichlet Multinomial — dmn.mle","text":"MLE Dirichlet Multinomial","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/dmn.mle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MLE for Dirichlet Multinomial — dmn.mle","text":"","code":"dmn.mle(counts, ...)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/dmn.mle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MLE for Dirichlet Multinomial — dmn.mle","text":"counts matrix rows samples columns categories ... additional arguments passed optim()","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/dmn.mle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MLE for Dirichlet Multinomial — dmn.mle","text":"list storing alpha parameter estimates, logLik, details convergence alphaestimated \\(alpha\\) parameters overdispersionOverdispersion value \\(1 + \\rho^2(n-1)\\) compared multinomial logLikvalue function scalescaling \\(\\alpha\\) parameters computed second optimization step evalsnumber function evaluations step 1 convergenceconvergence details step 1","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/dmn.mle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MLE for Dirichlet Multinomial — dmn.mle","text":"Maximize Dirichlet Multinomial (DMN) log-likelihood optim() using log likelihood function gradient.  method uses second round optimization estimate scale \\(\\alpha\\) parameters, necessary accurate estimation overdispersion metric. covariance counts category DMN distributed data \\(n(diag(p) - pp^T) (1 + \\rho^2(n-1))\\) \\(n\\) total counts, vector proportions  \\(p\\), \\(\\rho^2 = 1 / (a_0 + 1)\\) \\(a_0 = \\sum_i \\alpha_i\\).  count data overdispersed factor \\(1 + \\rho^2(n-1)\\) compared multinomial (MN) distribution.  \\(a_0\\) increases, DMN converges MN. See https://en.wikipedia.org/wiki/Dirichlet-multinomial_distribution#Matrix_notation","code":""},{"path":[]},{"path":"http://gabrielhoffman.github.io/crumblr/reference/dmn.mle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MLE for Dirichlet Multinomial — dmn.mle","text":"","code":"library(HMP) #> Loading required package: dirmult #>  #> Attaching package: ‘HMP’ #> The following object is masked from ‘package:dirmult’: #>  #>     weirMoM  set.seed(1)  n_samples = 1000 n_counts = 5000 alpha = c(500, 1000, 2000)  # Dirichlet.multinomial counts = Dirichlet.multinomial(rep(n_counts, n_samples), alpha)  fit = dmn.mle(counts)  fit #> $alpha #>    Taxa 1    Taxa 2    Taxa 3  #>  506.3936 1015.2977 2027.6383  #>  #> $overdispersion #> [1] 2.408038 #>  #> $logLik #> [1] -4777957 #>  #> $scale #> [1] 0.7098799 #>  #> $evals #> function gradient  #>        2        2  #>  #> $convergence #> [1] 0 #>   # overdispersion: true value a0 = sum(alpha) rhoSq = 1 / (a0 + 1) 1 + rhoSq*(n_counts-1)  #> [1] 2.427878  # multinomial, so overdispersion is 1 counts = t(rmultinom(n_samples, n_counts, prob=alpha / sum(alpha)))  dmn.mle(counts) #> $alpha #> [1]  33531.36  66971.13 133977.88 #>  #> $overdispersion #> [1] 1.021319 #>  #> $logLik #> [1] -4779160 #>  #> $scale #> [1] 1.084181 #>  #> $evals #> function gradient  #>       33       33  #>  #> $convergence #> [1] 0 #>"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/meanSdPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot row standard deviations versus row means — meanSdPlot","title":"Plot row standard deviations versus row means — meanSdPlot","text":"Diagnositic plot Student transform","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/meanSdPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot row standard deviations versus row means — meanSdPlot","text":"","code":"meanSdPlot(x)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/meanSdPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot row standard deviations versus row means — meanSdPlot","text":"x data matrix","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/meanSdPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot row standard deviations versus row means — meanSdPlot","text":"plot ggplot2","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/meanSdPlot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot row standard deviations versus row means — meanSdPlot","text":"Plot sd versus rank mean row like vsn::meanSdPlot.  Also show coefficient variation variances.  lower value indicates stronger variance stabilization","code":""},{"path":[]},{"path":"http://gabrielhoffman.github.io/crumblr/reference/meanSdPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot row standard deviations versus row means — meanSdPlot","text":"","code":"# set probability of each category prob = runif(300)  # number of samples n_samples = 1000  # number of counts nCounts = 3000  # simulate counts from multinomial counts = t(rmultinom(n_samples, size = nCounts, prob = prob)) colnames(counts) = paste0(\"cat_\", 1:length(prob)) rownames(counts) = paste0(\"sample_\", 1:n_samples)  # keep categories with at least 5 counts in at least 10 samples keep = colSums(counts > 5) > 10  # run crumblr on counts cobj = crumblr(counts[,keep])  # run student transform df_student = studentize(cobj)  # For each sample, plot rank of mean vs sd meanSdPlot(df_student) + ggtitle(\"crumblr student\")"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/plotScatterDensity.html","id":null,"dir":"Reference","previous_headings":"","what":"Scatter plot with 2D density using viridis colors — plotScatterDensity","title":"Scatter plot with 2D density using viridis colors — plotScatterDensity","text":"Scatter plot 2D density using viridis colors","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/plotScatterDensity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scatter plot with 2D density using viridis colors — plotScatterDensity","text":"","code":"plotScatterDensity(x, y, size = 1)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/plotScatterDensity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scatter plot with 2D density using viridis colors — plotScatterDensity","text":"x x-coordinates points plot y y-coordinates points plot size size point","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/plotScatterDensity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scatter plot with 2D density using viridis colors — plotScatterDensity","text":"plot ggplot2","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/plotScatterDensity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scatter plot with 2D density using viridis colors — plotScatterDensity","text":"","code":"# simulate data M = Rfast::rmvnorm(1000, mu=c(0,0), sigma=diag(1,2))  # create 2D density plot plotScatterDensity(M[,1], M[,2])"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/plotTreeTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot tree with results from multivariate testing — plotTreeTest","title":"Plot tree with results from multivariate testing — plotTreeTest","text":"Plot tree results multivariate testing","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/plotTreeTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot tree with results from multivariate testing — plotTreeTest","text":"","code":"plotTreeTest(tree, low = \"grey90\", mid = \"red\", high = \"darkred\")"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/plotTreeTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot tree with results from multivariate testing — plotTreeTest","text":"tree phylo object storing tree low low color gradient mid mid color gradient high high color gradient","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/plotTreeTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot tree with results from multivariate testing — plotTreeTest","text":"","code":"library(variancePartition)  # Load cell counts from Kang, et al. (2018) #  https://doi.org/10.1038/nbt.4042 data(IFNCellCounts)  # Apply crumblr transformation  cobj = crumblr(cellCounts)  # Use dream workflow to analyze each cell separately fit = dream(cobj, ~ StimStatus + ind, info) #> Fixed effect model, using limma directly... #> User can apply eBayes() afterwards... fit = eBayes(fit)  # Create a hierarchical cluster of cell types # NOTE: for example only # Create clustering using prior knowledge  # or single cell data hc = hclust(dist(t(cellCounts)))  # Perform multivariate test across the hierarchy res = treeTest( fit, cobj, hc, coef=\"StimStatusstim\", method=\"RE2C\")  # Plot hierarchy and testing results # Adjust xlim() until text fits in window  plotTreeTest(res) + xlim(0, 7)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/studentize-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Studentize observations using precision weights — studentize","title":"Studentize observations using precision weights — studentize","text":"Compute studentized observations precision weights scaling observation respective standard error","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/studentize-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Studentize observations using precision weights — studentize","text":"","code":"studentize(x)  # S4 method for EList studentize(x)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/studentize-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Studentize observations using precision weights — studentize","text":"x object storing data transformed","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/studentize-method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Studentize observations using precision weights — studentize","text":"matrix studentized values","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/studentize-method.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Studentize observations using precision weights — studentize","text":"Student transform scales observed value standard error.  x$weight stores inverse variance observation.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/studentize-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Studentize observations using precision weights — studentize","text":"","code":"# set probability of each category prob = c(0.1, 0.2, 0.3, 0.5)  # number of total counts countsTotal = 300  # number of samples n_samples = 100  # simulate counts from multinomial counts = t(rmultinom(n_samples, size = countsTotal, prob = prob)) colnames(counts) = paste0(\"cat_\", 1:length(prob)) rownames(counts) = paste0(\"sample_\", 1:n_samples)  # run crumblr on counts cobj = crumblr(counts)  # apply student transform  df_student = studentize(cobj)  # Perform PCA on student transformed data pca = prcomp(t(df_student)) df_pca = as.data.frame(pca$x)  ggplot(df_pca, aes(PC1, PC2)) + geom_point() + theme_classic() + theme(aspect.ratio=1)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/treeTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform multivariate testing along a hierarchy — treeTest","title":"Perform multivariate testing along a hierarchy — treeTest","text":"Perform multivariate testing using mvTest() along nodes tree","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/treeTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform multivariate testing along a hierarchy — treeTest","text":"","code":"treeTest(   fit,   obj,   hc,   coef,   method = c(\"RE2C\", \"FE\", \"tstat\", \"sidak\", \"fisher\") )"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/treeTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform multivariate testing along a hierarchy — treeTest","text":"fit MArrayLM object return lmFit() dream() obj EList object returned voom() hc hierarchical clustering hclust object coef name coefficient extracted method statistical method used perform multivariate test.  See details. 'RE2C' random effect test heterogeneity estimated coefficients models covariance coefficients, also incorporates fixed effects test . 'FE' fixed effect test models covariance coefficients.  'tstat' combines t-statistics models covariance coefficients. 'sidak' returns smallest p-value accounting number tests. 'fisher' combines p-value using Fisher's method assuming independent tests.","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/treeTest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform multivariate testing along a hierarchy — treeTest","text":"See package remaCor details remaCor::RE2C() test, see remaCor::LS() details fixed effect test.  1 feature selected, original t-statistic p-value returned.","code":""},{"path":[]},{"path":"http://gabrielhoffman.github.io/crumblr/reference/treeTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform multivariate testing along a hierarchy — treeTest","text":"","code":"library(variancePartition)  # Load cell counts from Kang, et al. (2018) #  https://doi.org/10.1038/nbt.4042 data(IFNCellCounts)  # Apply crumblr transformation  cobj = crumblr(cellCounts)  # Use dream workflow to analyze each cell separately fit = dream(cobj, ~ StimStatus + ind, info) #> Fixed effect model, using limma directly... #> User can apply eBayes() afterwards... fit = eBayes(fit)  # Create a hierarchical cluster of cell types # NOTE: for example only # Create clustering using prior knowledge  # or single cell data hc = hclust(dist(t(cellCounts)))  # Perform multivariate test across the hierarchy res = treeTest( fit, cobj, hc, coef=\"StimStatusstim\", method=\"RE2C\")  # Plot hierarchy and testing results # Adjust xlim() until text fits in window  plotTreeTest(res) + xlim(0, 7)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/vst-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance stabilizing transform from precision weights — vst","title":"Variance stabilizing transform from precision weights — vst","text":"Compute variance stabilizing transform (VST) precision weights scaling observation respective weights","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/vst-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance stabilizing transform from precision weights — vst","text":"","code":"vst(x)  # S4 method for EList vst(x)"},{"path":"http://gabrielhoffman.github.io/crumblr/reference/vst-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance stabilizing transform from precision weights — vst","text":"x object storing data transformed","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/vst-method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance stabilizing transform from precision weights — vst","text":"matrix variance stabilized values","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/vst-method.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variance stabilizing transform from precision weights — vst","text":"variance stabilizing transform usually described terms parametric model observed data.  Instead, inverse variance observation stored x$weight VST divides observed data scaled standard deviations","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/reference/vst-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance stabilizing transform from precision weights — vst","text":"","code":"# set probability of each category prob = c(0.1, 0.2, 0.3, 0.5)  # number of total counts countsTotal = 300  # number of samples n_samples = 100  # simulate counts from multinomial counts = t(rmultinom(n_samples, size = countsTotal, prob = prob)) colnames(counts) = paste0(\"cat_\", 1:length(prob)) rownames(counts) = paste0(\"sample_\", 1:n_samples)  # run crumblr on counts cobj = crumblr(counts)  # apply variance stabilizing transform (vst) df_vst = vst(cobj)  # Perform PCA on VST transformed data pca = prcomp(t(df_vst)) df_pca = as.data.frame(pca$x)  ggplot(df_pca, aes(PC1, PC2)) + geom_point() + theme_classic() + theme(aspect.ratio=1)"},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-0992","dir":"Changelog","previous_headings":"","what":"crumblr 0.99.2","title":"crumblr 0.99.2","text":"update plotTreeTest() Use variancePartition dependency GitHub","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-0991","dir":"Changelog","previous_headings":"","what":"crumblr 0.99.1","title":"crumblr 0.99.1","text":"add functions perform mvTest() trees","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-0990","dir":"Changelog","previous_headings":"","what":"crumblr 0.99.0","title":"crumblr 0.99.0","text":"Jun 24, 2022 Fix version number compatibility Bioconductor","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-107","dir":"Changelog","previous_headings":"","what":"crumblr 1.0.7","title":"crumblr 1.0.7","text":"Feb 1, 2022 fix vst() add plots plotScatterDensity() meanSdPlot() VST add vignette vst.Rmd","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-106","dir":"Changelog","previous_headings":"","what":"crumblr 1.0.6","title":"crumblr 1.0.6","text":"Jan 31, 2022 add logo, example data","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-105","dir":"Changelog","previous_headings":"","what":"crumblr 1.0.5","title":"crumblr 1.0.5","text":"Dec 27, 2021 add dmn.mle() use generic crumblr() function","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-104","dir":"Changelog","previous_headings":"","what":"crumblr 1.0.4","title":"crumblr 1.0.4","text":"Dec 23, 2021 Update vignette export clr()","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-103","dir":"Changelog","previous_headings":"","what":"crumblr 1.0.3","title":"crumblr 1.0.3","text":"Dec 20, 2021 fix vst bug","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-102","dir":"Changelog","previous_headings":"","what":"crumblr 1.0.2","title":"crumblr 1.0.2","text":"Dec 20, 2021 add vst","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-101","dir":"Changelog","previous_headings":"","what":"crumblr 1.0.1","title":"crumblr 1.0.1","text":"Oct 29, 2021 handle data.frame","code":""},{"path":"http://gabrielhoffman.github.io/crumblr/news/index.html","id":"crumblr-100","dir":"Changelog","previous_headings":"","what":"crumblr 1.0.0","title":"crumblr 1.0.0","text":"Oct 28, 2021 Initial version","code":""}]
